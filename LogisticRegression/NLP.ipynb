{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc. (AAPL) CEO Tim Cook on Q4 2020 Resu...</td>\n",
       "      <td>/article/4382943-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>10/29/2020</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc. (AAPL) CEO Tim Cook on Q3 2020 Resu...</td>\n",
       "      <td>/article/4362707-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>7/30/2020</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple Inc. (AAPL) CEO Tim Cook on Q2 2020 Resu...</td>\n",
       "      <td>/article/4341792-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>4/30/2020</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple Inc. (AAPL) CEO Tim Cook on Q1 2020 Resu...</td>\n",
       "      <td>/article/4319666-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>1/28/2020</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AbbVie Inc.'s (ABBV) CEO Rick Gonzalez on Q3 2...</td>\n",
       "      <td>/article/4383381-abbvie-inc-s-abbv-ceo-rick-go...</td>\n",
       "      <td>10/30/2020</td>\n",
       "      <td>ABBV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Walmart, Inc. (WMT) CEO Doug McMillon on Q1 20...</td>\n",
       "      <td>/article/4348814-walmart-inc-wmt-ceo-doug-mcmi...</td>\n",
       "      <td>5/19/2020</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Exxon Mobil Corporation (XOM) Q3 2020 Results ...</td>\n",
       "      <td>/article/4383411-exxon-mobil-corporation-xom-q...</td>\n",
       "      <td>10/30/2020</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Exxon Mobil Corp (XOM) Q2 2020 Results - Earni...</td>\n",
       "      <td>/article/4363013-exxon-mobil-corp-xom-q2-2020-...</td>\n",
       "      <td>7/31/2020</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Exxon Mobil Corporation (XOM) CEO Darren Woods...</td>\n",
       "      <td>/article/4342148-exxon-mobil-corporation-xom-c...</td>\n",
       "      <td>5/1/2020</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Exxon Mobil Corporation (XOM) CEO Darren Woods...</td>\n",
       "      <td>/article/4320707-exxon-mobil-corporation-xom-c...</td>\n",
       "      <td>1/31/2020</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Apple Inc. (AAPL) CEO Tim Cook on Q4 2020 Resu...   \n",
       "1     Apple Inc. (AAPL) CEO Tim Cook on Q3 2020 Resu...   \n",
       "2     Apple Inc. (AAPL) CEO Tim Cook on Q2 2020 Resu...   \n",
       "3     Apple Inc. (AAPL) CEO Tim Cook on Q1 2020 Resu...   \n",
       "8     AbbVie Inc.'s (ABBV) CEO Rick Gonzalez on Q3 2...   \n",
       "...                                                 ...   \n",
       "1031  Walmart, Inc. (WMT) CEO Doug McMillon on Q1 20...   \n",
       "1035  Exxon Mobil Corporation (XOM) Q3 2020 Results ...   \n",
       "1037  Exxon Mobil Corp (XOM) Q2 2020 Results - Earni...   \n",
       "1039  Exxon Mobil Corporation (XOM) CEO Darren Woods...   \n",
       "1041  Exxon Mobil Corporation (XOM) CEO Darren Woods...   \n",
       "\n",
       "                                                    URL        Date Symbol  \n",
       "0     /article/4382943-apple-inc-aapl-ceo-tim-cook-o...  10/29/2020   AAPL  \n",
       "1     /article/4362707-apple-inc-aapl-ceo-tim-cook-o...   7/30/2020   AAPL  \n",
       "2     /article/4341792-apple-inc-aapl-ceo-tim-cook-o...   4/30/2020   AAPL  \n",
       "3     /article/4319666-apple-inc-aapl-ceo-tim-cook-o...   1/28/2020   AAPL  \n",
       "8     /article/4383381-abbvie-inc-s-abbv-ceo-rick-go...  10/30/2020   ABBV  \n",
       "...                                                 ...         ...    ...  \n",
       "1031  /article/4348814-walmart-inc-wmt-ceo-doug-mcmi...   5/19/2020    WMT  \n",
       "1035  /article/4383411-exxon-mobil-corporation-xom-q...  10/30/2020    XOM  \n",
       "1037  /article/4363013-exxon-mobil-corp-xom-q2-2020-...   7/31/2020    XOM  \n",
       "1039  /article/4342148-exxon-mobil-corporation-xom-c...    5/1/2020    XOM  \n",
       "1041  /article/4320707-exxon-mobil-corporation-xom-c...   1/31/2020    XOM  \n",
       "\n",
       "[402 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_path = os.path.join(\"..\", \"transcript_list.csv\")\n",
    "df_all = pd.read_csv(transcript_path)\n",
    "df_ECT = df_all[df_all['Title'].str.contains(\"Earnings Call Transcript\")]\n",
    "df_ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_ECT['Title'].tolist()\n",
    "# titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a file: file\n",
    "one_title = titles[0]\n",
    "#! need to change file_path. Specify 'sandp100' or 'sandp500'\n",
    "# current path: ..\\transcripts\\Apple Inc. (AAPL) CEO Tim Cook on Q4 2020 Results - Earnings Call Transcript.txt\n",
    "file_path = os.path.join('..', 'transcripts', 'sandp500', one_title +'.txt') \n",
    "file = open(file_path,mode='r')\n",
    " \n",
    "# read all lines at once\n",
    "all_of_it = file.read()\n",
    " \n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lamqi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lamqi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lamqi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#all_of_it\n",
    "from utils import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "processed_text = preprocess_text(all_of_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4033"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamqi\\AppData\\Local\\Temp\\ipykernel_25828\\4250516910.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ECT['body'] = ''\n"
     ]
    }
   ],
   "source": [
    "df_ECT['body'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT = df_ECT.set_index('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Apple Inc. (AAPL) CEO Tim Cook on Q4 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4382943-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>10/29/2020</td>\n",
       "      <td>AAPL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple Inc. (AAPL) CEO Tim Cook on Q3 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4362707-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>7/30/2020</td>\n",
       "      <td>AAPL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple Inc. (AAPL) CEO Tim Cook on Q2 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4341792-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>4/30/2020</td>\n",
       "      <td>AAPL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple Inc. (AAPL) CEO Tim Cook on Q1 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4319666-apple-inc-aapl-ceo-tim-cook-o...</td>\n",
       "      <td>1/28/2020</td>\n",
       "      <td>AAPL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AbbVie Inc.'s (ABBV) CEO Rick Gonzalez on Q3 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4383381-abbvie-inc-s-abbv-ceo-rick-go...</td>\n",
       "      <td>10/30/2020</td>\n",
       "      <td>ABBV</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart, Inc. (WMT) CEO Doug McMillon on Q1 2021 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4348814-walmart-inc-wmt-ceo-doug-mcmi...</td>\n",
       "      <td>5/19/2020</td>\n",
       "      <td>WMT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exxon Mobil Corporation (XOM) Q3 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4383411-exxon-mobil-corporation-xom-q...</td>\n",
       "      <td>10/30/2020</td>\n",
       "      <td>XOM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exxon Mobil Corp (XOM) Q2 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4363013-exxon-mobil-corp-xom-q2-2020-...</td>\n",
       "      <td>7/31/2020</td>\n",
       "      <td>XOM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exxon Mobil Corporation (XOM) CEO Darren Woods on Q1 2020 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4342148-exxon-mobil-corporation-xom-c...</td>\n",
       "      <td>5/1/2020</td>\n",
       "      <td>XOM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exxon Mobil Corporation (XOM) CEO Darren Woods on Q4 2019 Results - Earnings Call Transcript</th>\n",
       "      <td>/article/4320707-exxon-mobil-corporation-xom-c...</td>\n",
       "      <td>1/31/2020</td>\n",
       "      <td>XOM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>402 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  URL  \\\n",
       "Title                                                                                                   \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q4 2020 Resul...  /article/4382943-apple-inc-aapl-ceo-tim-cook-o...   \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q3 2020 Resul...  /article/4362707-apple-inc-aapl-ceo-tim-cook-o...   \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q2 2020 Resul...  /article/4341792-apple-inc-aapl-ceo-tim-cook-o...   \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q1 2020 Resul...  /article/4319666-apple-inc-aapl-ceo-tim-cook-o...   \n",
       "AbbVie Inc.'s (ABBV) CEO Rick Gonzalez on Q3 20...  /article/4383381-abbvie-inc-s-abbv-ceo-rick-go...   \n",
       "...                                                                                               ...   \n",
       "Walmart, Inc. (WMT) CEO Doug McMillon on Q1 202...  /article/4348814-walmart-inc-wmt-ceo-doug-mcmi...   \n",
       "Exxon Mobil Corporation (XOM) Q3 2020 Results -...  /article/4383411-exxon-mobil-corporation-xom-q...   \n",
       "Exxon Mobil Corp (XOM) Q2 2020 Results - Earnin...  /article/4363013-exxon-mobil-corp-xom-q2-2020-...   \n",
       "Exxon Mobil Corporation (XOM) CEO Darren Woods ...  /article/4342148-exxon-mobil-corporation-xom-c...   \n",
       "Exxon Mobil Corporation (XOM) CEO Darren Woods ...  /article/4320707-exxon-mobil-corporation-xom-c...   \n",
       "\n",
       "                                                          Date Symbol body  \n",
       "Title                                                                       \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q4 2020 Resul...  10/29/2020   AAPL       \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q3 2020 Resul...   7/30/2020   AAPL       \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q2 2020 Resul...   4/30/2020   AAPL       \n",
       "Apple Inc. (AAPL) CEO Tim Cook on Q1 2020 Resul...   1/28/2020   AAPL       \n",
       "AbbVie Inc.'s (ABBV) CEO Rick Gonzalez on Q3 20...  10/30/2020   ABBV       \n",
       "...                                                        ...    ...  ...  \n",
       "Walmart, Inc. (WMT) CEO Doug McMillon on Q1 202...   5/19/2020    WMT       \n",
       "Exxon Mobil Corporation (XOM) Q3 2020 Results -...  10/30/2020    XOM       \n",
       "Exxon Mobil Corp (XOM) Q2 2020 Results - Earnin...   7/31/2020    XOM       \n",
       "Exxon Mobil Corporation (XOM) CEO Darren Woods ...    5/1/2020    XOM       \n",
       "Exxon Mobil Corporation (XOM) CEO Darren Woods ...   1/31/2020    XOM       \n",
       "\n",
       "[402 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT.at[titles[0], 'body'] = all_of_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['body_tokens'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    try:\n",
    "        file_path = os.path.join('..', 'transcripts', title +'.txt')\n",
    "        file = open(file_path,mode='r')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        processed_text = preprocess_text(text)\n",
    "        df_ECT.at[title, 'body'] = text\n",
    "        df_ECT.at[title, 'body_tokens'] = processed_text\n",
    "    except:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index          19768\n",
       "URL             3216\n",
       "Date            3216\n",
       "Symbol          3216\n",
       "body            3216\n",
       "body_tokens     3216\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_ECT.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['Date'] = pd.to_datetime(df_ECT['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['date_plus_28'] = pd.to_datetime(df_ECT['Date']) + dt.timedelta(28) #plus 28 days\n",
    "df_ECT['date_plus_7'] = pd.to_datetime(df_ECT['Date']) + dt.timedelta(7) #plus 7 days\n",
    "df_ECT['date_plus_1'] = pd.to_datetime(df_ECT['Date']) + dt.timedelta(1) #plus 1 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj_Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>74.444603</td>\n",
       "      <td>75.087502</td>\n",
       "      <td>75.150002</td>\n",
       "      <td>73.797501</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>135,480,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>73.720840</td>\n",
       "      <td>74.357498</td>\n",
       "      <td>75.144997</td>\n",
       "      <td>74.125000</td>\n",
       "      <td>74.287498</td>\n",
       "      <td>146,322,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>74.308266</td>\n",
       "      <td>74.949997</td>\n",
       "      <td>74.989998</td>\n",
       "      <td>73.187500</td>\n",
       "      <td>73.447502</td>\n",
       "      <td>118,387,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>73.958794</td>\n",
       "      <td>74.597504</td>\n",
       "      <td>75.224998</td>\n",
       "      <td>74.370003</td>\n",
       "      <td>74.959999</td>\n",
       "      <td>108,872,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>75.148521</td>\n",
       "      <td>75.797501</td>\n",
       "      <td>76.110001</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>74.290001</td>\n",
       "      <td>132,079,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25548</th>\n",
       "      <td>25548</td>\n",
       "      <td>XOM</td>\n",
       "      <td>Exxon Mobil Corp.</td>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>41.849998</td>\n",
       "      <td>41.380001</td>\n",
       "      <td>41.650002</td>\n",
       "      <td>8,039,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25549</th>\n",
       "      <td>25549</td>\n",
       "      <td>XOM</td>\n",
       "      <td>Exxon Mobil Corp.</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>41.740002</td>\n",
       "      <td>42.549999</td>\n",
       "      <td>41.520000</td>\n",
       "      <td>41.689999</td>\n",
       "      <td>23,877,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25550</th>\n",
       "      <td>25550</td>\n",
       "      <td>XOM</td>\n",
       "      <td>Exxon Mobil Corp.</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>41.270000</td>\n",
       "      <td>41.270000</td>\n",
       "      <td>42.119999</td>\n",
       "      <td>41.200001</td>\n",
       "      <td>42.040001</td>\n",
       "      <td>20,287,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25551</th>\n",
       "      <td>25551</td>\n",
       "      <td>XOM</td>\n",
       "      <td>Exxon Mobil Corp.</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>41.599998</td>\n",
       "      <td>42.419998</td>\n",
       "      <td>41.270000</td>\n",
       "      <td>41.330002</td>\n",
       "      <td>23,807,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25552</th>\n",
       "      <td>25552</td>\n",
       "      <td>XOM</td>\n",
       "      <td>Exxon Mobil Corp.</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>41.220001</td>\n",
       "      <td>41.220001</td>\n",
       "      <td>41.680000</td>\n",
       "      <td>40.970001</td>\n",
       "      <td>41.470001</td>\n",
       "      <td>22,769,300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25553 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 Symbol               Name       Date  Adj_Close      Close  \\\n",
       "0               0   AAPL         Apple Inc. 2020-01-02  74.444603  75.087502   \n",
       "1               1   AAPL         Apple Inc. 2020-01-03  73.720840  74.357498   \n",
       "2               2   AAPL         Apple Inc. 2020-01-06  74.308266  74.949997   \n",
       "3               3   AAPL         Apple Inc. 2020-01-07  73.958794  74.597504   \n",
       "4               4   AAPL         Apple Inc. 2020-01-08  75.148521  75.797501   \n",
       "...           ...    ...                ...        ...        ...        ...   \n",
       "25548       25548    XOM  Exxon Mobil Corp. 2020-12-24  41.599998  41.599998   \n",
       "25549       25549    XOM  Exxon Mobil Corp. 2020-12-28  41.740002  41.740002   \n",
       "25550       25550    XOM  Exxon Mobil Corp. 2020-12-29  41.270000  41.270000   \n",
       "25551       25551    XOM  Exxon Mobil Corp. 2020-12-30  41.599998  41.599998   \n",
       "25552       25552    XOM  Exxon Mobil Corp. 2020-12-31  41.220001  41.220001   \n",
       "\n",
       "            High        Low       Open       Volume  \n",
       "0      75.150002  73.797501  74.059998  135,480,400  \n",
       "1      75.144997  74.125000  74.287498  146,322,800  \n",
       "2      74.989998  73.187500  73.447502  118,387,200  \n",
       "3      75.224998  74.370003  74.959999  108,872,000  \n",
       "4      76.110001  74.290001  74.290001  132,079,200  \n",
       "...          ...        ...        ...          ...  \n",
       "25548  41.849998  41.380001  41.650002    8,039,000  \n",
       "25549  42.549999  41.520000  41.689999   23,877,500  \n",
       "25550  42.119999  41.200001  42.040001   20,287,700  \n",
       "25551  42.419998  41.270000  41.330002   23,807,300  \n",
       "25552  41.680000  40.970001  41.470001   22,769,300  \n",
       "\n",
       "[25553 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load price data\n",
    "#! \"combined_snp100_data.csv\" currently in \"sentiment_analysis_folder\"\n",
    "price_file_path = os.path.join('..', 'sentiment_analysis_folder', 'combined_snp100_data.csv')\n",
    "pricing_df = pd.read_csv(price_file_path)\n",
    "pricing_df['Date'] = pd.to_datetime(pricing_df['Date'])\n",
    "pricing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['date_plus_28'] = pd.to_datetime(df_ECT['date_plus_28'], format='%Y-%m-%d', errors='coerce').dt.date # If 'coerce', then invalid parsing will be set as NaT.\n",
    "df_ECT['date_plus_7'] = pd.to_datetime(df_ECT['date_plus_7'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "df_ECT['date_plus_1'] = pd.to_datetime(df_ECT['date_plus_1'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "df_ECT['Date'] = pd.to_datetime(df_ECT['Date'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "pricing_df['Date'] = pd.to_datetime(pricing_df['Date'], format='%Y-%m-%d', errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_date = df_ECT['Date'][0]\n",
    "search_ticker = df_ECT['Symbol'][0]\n",
    "\n",
    "#if (pricing_df[(pricing_df[\"Date\"]==search_date) & (pricing_df[\"Symbol\"]==search_ticker)].iloc[0]['Close']):\n",
    "#print(pricing_df[(pricing_df[\"Date\"]==search_date) & (pricing_df[\"Symbol\"]==search_ticker)].iloc[0]['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPriceOnDayExact(search_ticker, search_date):\n",
    "    return pricing_df[(pricing_df[\"Date\"]==search_date) & (pricing_df[\"Symbol\"]==search_ticker)].iloc[0]['Close']    \n",
    "\n",
    "#the below function will return closing price given a ticker and day, if the market was open day, if it was not, it checks the next day, and then the day after that\n",
    "def getPriceOnDay(search_ticker, search_date):\n",
    "    dates = pricing_df[pricing_df['Symbol']==search_ticker][\"Date\"].tolist()\n",
    "    if (search_date in dates):\n",
    "        return pricing_df[(pricing_df[\"Date\"]==search_date) & (pricing_df[\"Symbol\"]==search_ticker)].iloc[0]['Close']\n",
    "    elif ( (search_date + dt.timedelta(1)) in dates):\n",
    "        search_date = search_date + dt.timedelta(1)\n",
    "        return pricing_df[(pricing_df[\"Date\"]==search_date) & (pricing_df[\"Symbol\"]==search_ticker)].iloc[0]['Close']\n",
    "    elif ( (search_date + dt.timedelta(2)) in dates):\n",
    "        search_date = search_date + dt.timedelta(2)\n",
    "        return pricing_df[(pricing_df[\"Date\"]==search_date) & (pricing_df[\"Symbol\"]==search_ticker)].iloc[0]['Close']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#calculate return given beginning and ending price\n",
    "def returnOnInvestment(begin_price, end_price):\n",
    "    return_on_investment = (end_price/begin_price)-1\n",
    "    return return_on_investment\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df['Date'] = pd.to_datetime(pricing_df['Date'], '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_ECT.iloc[:10].iterrows():\n",
    "    date = row['Date']\n",
    "    ticker = row['Symbol']\n",
    "    print(getPriceOnDay(ticker, date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['Price'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['Date']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['price_plus_28'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['date_plus_28']), axis=1)\n",
    "df_ECT['price_plus_7'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['date_plus_7']), axis=1)\n",
    "df_ECT['price_plus_1'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['date_plus_1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['return_28'] = df_ECT.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_28']), axis=1)\n",
    "df_ECT['return_7'] = df_ECT.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_7']), axis=1)\n",
    "df_ECT['return_1'] = df_ECT.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_1']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['Price'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['Date']), axis=1)\n",
    "df_ECT['price_plus_28'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['date_plus_28']), axis=1)\n",
    "df_ECT['price_plus_7'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['date_plus_7']), axis=1)\n",
    "df_ECT['price_plus_1'] = df_ECT.apply(lambda x: getPriceOnDay(x['Symbol'], x['date_plus_1']), axis=1)\n",
    "df_ECT['return_28'] = df_ECT.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_28']), axis=1)\n",
    "df_ECT['return_7'] = df_ECT.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_7']), axis=1)\n",
    "df_ECT['return_1'] = df_ECT.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT = df_ECT.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT = df_ECT.drop(columns=['rating', 'return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(price_movement):\n",
    "    if price_movement > .03:\n",
    "        return 'buy'\n",
    "    elif price_movement < -.03:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return 'hold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['rating_28'] = df_ECT.apply(lambda x: rating(x['return_28']), axis=1)\n",
    "df_ECT['rating_7'] = df_ECT.apply(lambda x: rating(x['return_7']), axis=1)\n",
    "df_ECT['rating_1'] = df_ECT.apply(lambda x: rating(x['return_1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT['body_str'] = df_ECT['body'].apply(lambda x : ' '.join(preprocess_text(x, min_word_length=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT = df_ECT.drop(columns=['body_tokens', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_no_tokens = df_ECT.drop(columns=['body', 'body_tokens', 'body_str'])\n",
    "df_ECT_no_tokens.to_csv('ECTs_with_price_and_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = df_ECT.sample(frac=1)\n",
    "result = np.array_split(shuffled, 2)\n",
    "train_df = result[0]\n",
    "test_df = result[1]\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Custom preprocessing function\n",
    "from utils import preprocess_text\n",
    "\n",
    "# Vectorization methods\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = result[0]\n",
    "test_df = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "[`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) is a simple tool that turns raw text into feature vectors. We vectorize the text in 2 steps: \n",
    "1. First, we `fit`, the training data to our vectorizer to compute the vocabulary (feature set). \n",
    "2. Then, we `transform` with our text for both train and test to count the number occurrences for each word in our vocabulary.\n",
    "\n",
    "The output of the CountVectorizer's `transform` task is a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix), which condenses the matrix values to avoid storing an excessive amount of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# learn the vocabulary for the training set\n",
    "vectorizer.fit(train_df['body_str'])\n",
    "\n",
    "# count the number of occurrences for our vocabulary terms within train & test\n",
    "count_train_vecs = vectorizer.transform(train_df['body_str'])\n",
    "count_test_vecs = vectorizer.transform(test_df['body_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the size of our vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of documents: {count_train_vecs.shape[0]}\")\n",
    "print(f\"Size of vocabulary: {count_train_vecs.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(f\"Number of TRAINING non-zero features: {count_train_vecs.nnz}\")\n",
    "print(f\"Number of TRAINING zero features: {(count_train_vecs.shape[0]*count_train_vecs.shape[1])-count_train_vecs.nnz}\")\n",
    "\n",
    "# Test\n",
    "print(f\"Number of TEST non-zero features: {count_test_vecs.nnz}\")\n",
    "print(f\"Number of TEST zero features: {(count_test_vecs.shape[0]*count_test_vecs.shape[1])-count_test_vecs.nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(train_df['body_str'])\n",
    "tfidf_train_vecs = tfidf_vectorizer.transform(train_df['body_str'])\n",
    "tfidf_test_vecs = tfidf_vectorizer.transform(test_df['body_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf_train_vecs.toarray(), \n",
    "                         columns=tfidf_vectorizer.get_feature_names())[:30].T\n",
    "df_tfidf.tail(25).style.background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "count_logReg.fit(count_train_vecs, train_df['rating_1'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = count_logReg.score(count_test_vecs, test_df['rating_1'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "tfidf_logReg.fit(tfidf_train_vecs, train_df['rating_1'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = tfidf_logReg.score(tfidf_test_vecs, test_df['rating_1'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "count_logReg.fit(count_train_vecs, train_df['rating_7'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = count_logReg.score(count_test_vecs, test_df['rating_7'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "tfidf_logReg.fit(tfidf_train_vecs, train_df['rating_7'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = tfidf_logReg.score(tfidf_test_vecs, test_df['rating_7'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "count_logReg.fit(count_train_vecs, train_df['rating_28'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = count_logReg.score(count_test_vecs, test_df['rating_28'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "tfidf_logReg.fit(tfidf_train_vecs, train_df['rating_28'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = tfidf_logReg.score(tfidf_test_vecs, test_df['rating_28'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['rating_1']=='buy'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['rating_1']=='sell'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['rating_1']=='hold'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "147 / 202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from utils import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load price data\n",
    "price_file_path = os.path.join('..', 'combined_sandp500_data2015to2020.csv')\n",
    "pricing_df_500 = pd.read_csv(price_file_path)\n",
    "pricing_df_500['Date'] = pd.to_datetime(pricing_df['Date'])\n",
    "pricing_df_500 = pricing_df_500.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join('..', 'transcript_list_500.csv')\n",
    "df_ECT_500 = pd.read_csv(file_path)\n",
    "df_ECT_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPriceOnDayExact500(search_ticker, search_date):\n",
    "    return pricing_df_500[(pricing_df_500[\"Date\"]==search_date) & (pricing_df_500[\"Symbol\"]==search_ticker)].iloc[0]['Close']    \n",
    "\n",
    "#the below function will return closing price given a ticker and day, if the market was open day, if it was not, it checks the next day, and then the day after that\n",
    "def getPriceOnDay500(search_ticker, search_date):\n",
    "    dates = pricing_df[pricing_df['Symbol']==search_ticker][\"Date\"].tolist()\n",
    "    if (search_date in dates):\n",
    "        return pricing_df_500[(pricing_df_500[\"Date\"]==search_date) & (pricing_df_500[\"Symbol\"]==search_ticker)].iloc[0]['Close']\n",
    "    elif ( (search_date + dt.timedelta(1)) in dates):\n",
    "        search_date = search_date + dt.timedelta(1)\n",
    "        return pricing_df_500[(pricing_df_500[\"Date\"]==search_date) & (pricing_df_500[\"Symbol\"]==search_ticker)].iloc[0]['Close']\n",
    "    elif ( (search_date + dt.timedelta(2)) in dates):\n",
    "        search_date = search_date + dt.timedelta(2)\n",
    "        return pricing_df_500[(pricing_df_500[\"Date\"]==search_date) & (pricing_df_500[\"Symbol\"]==search_ticker)].iloc[0]['Close']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#calculate return given beginning and ending price\n",
    "def returnOnInvestment(begin_price, end_price):\n",
    "    return_on_investment = (end_price/begin_price)-1\n",
    "    return return_on_investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500['date_plus_28'] = pd.to_datetime(df_ECT_500['date']) + dt.timedelta(28)\n",
    "df_ECT_500['date_plus_7'] = pd.to_datetime(df_ECT_500['date']) + dt.timedelta(7)\n",
    "df_ECT_500['date_plus_1'] = pd.to_datetime(df_ECT_500['date']) + dt.timedelta(1)\n",
    "df_ECT_500['date_plus_28'] = pd.to_datetime(df_ECT_500['date_plus_28'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "df_ECT_500['date_plus_7'] = pd.to_datetime(df_ECT_500['date_plus_7'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "df_ECT_500['date_plus_1'] = pd.to_datetime(df_ECT_500['date_plus_1'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "df_ECT_500['date'] = pd.to_datetime(df_ECT_500['date'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "pricing_df_500['Date'] = pd.to_datetime(pricing_df_500['Date'], format='%Y-%m-%d', errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500['Price'] = df_ECT_500.apply(lambda x: getPriceOnDay500(x['Symbol'], x['date']), axis=1)\n",
    "df_ECT_500['price_plus_28'] = df_ECT_500.apply(lambda x: getPriceOnDay500(x['Symbol'], x['date_plus_28']), axis=1)\n",
    "df_ECT_500['price_plus_7'] = df_ECT_500.apply(lambda x: getPriceOnDay500(x['Symbol'], x['date_plus_7']), axis=1)\n",
    "df_ECT_500['price_plus_1'] = df_ECT_500.apply(lambda x: getPriceOnDay500(x['Symbol'], x['date_plus_1']), axis=1)\n",
    "df_ECT_500['return_28'] = df_ECT_500.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_28']), axis=1)\n",
    "df_ECT_500['return_7'] = df_ECT_500.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_7']), axis=1)\n",
    "df_ECT_500['return_1'] = df_ECT_500.apply(lambda x: returnOnInvestment(x['Price'], x['price_plus_1']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500['rating_28'] = df_ECT_500.apply(lambda x: rating(x['return_28']), axis=1)\n",
    "df_ECT_500['rating_7'] = df_ECT_500.apply(lambda x: rating(x['return_7']), axis=1)\n",
    "df_ECT_500['rating_1'] = df_ECT_500.apply(lambda x: rating(x['return_1']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500.to_csv('df_ECT_500.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500 = pd.read_csv('df_ECT_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df_ECT_500['title'].tolist()\n",
    "#titles\n",
    "df_ECT_500 = df_ECT_500.set_index('title')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500['body'] = ''\n",
    "df_ECT_500['body_tokens'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    file_path = os.path.join('..', 'transcripts', 'sandp500', title +'.txt')\n",
    "    try:        \n",
    "        file = open(file_path,mode='r')\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "        processed_text = preprocess_text(text)\n",
    "        df_ECT_500.at[title, 'body'] = text\n",
    "        df_ECT_500.at[title, 'body_tokens'] = processed_text\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500_with = df_ECT_500.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500_with_text = df_ECT_500\n",
    "df_ECT_500_with_text.to_csv(\"df_ECT_500.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500['body_str'] = df_ECT_500['body'].apply(lambda x : ' '.join(preprocess_text(x, min_word_length=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ECT_500['tfidf_vector'] = df_ECT_500[''].apply(lambda x: tfidf_vectorizer.fit(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe with 80% \n",
    "# values of original dataframe \n",
    "train_df = df_ECT_500.sample(frac = 0.80) \n",
    "  \n",
    "# Creating dataframe with  \n",
    "# rest of the 20% values \n",
    "test_df = df_ECT_500.drop(train_df.index) \n",
    "  \n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_train_vecs[0].toarray()\n",
    "tfidf_train_vecs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Vectorization methods\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# learn the vocabulary for the training set\n",
    "vectorizer.fit(train_df['body_str'])\n",
    "\n",
    "# count the number of occurrences for our vocabulary terms within train & test\n",
    "count_train_vecs = vectorizer.transform(train_df['body_str'])\n",
    "count_test_vecs = vectorizer.transform(test_df['body_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of documents: {count_train_vecs.shape[0]}\")\n",
    "print(f\"Size of vocabulary: {count_train_vecs.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(f\"Number of TRAINING non-zero features: {count_train_vecs.nnz}\")\n",
    "print(f\"Number of TRAINING zero features: {(count_train_vecs.shape[0]*count_train_vecs.shape[1])-count_train_vecs.nnz}\")\n",
    "\n",
    "# Test\n",
    "print(f\"Number of TEST non-zero features: {count_test_vecs.nnz}\")\n",
    "print(f\"Number of TEST zero features: {(count_test_vecs.shape[0]*count_test_vecs.shape[1])-count_test_vecs.nnz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "tfidf_vectorizer.fit(train_df['body_str'])\n",
    "tfidf_train_vecs = tfidf_vectorizer.transform(train_df['body_str'])\n",
    "tfidf_test_vecs = tfidf_vectorizer.transform(test_df['body_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg_1 = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "count_logReg_1.fit(count_train_vecs, train_df['rating_1'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_count_logReg_1 = count_logReg_1.score(count_test_vecs, test_df['rating_1'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy_count_logReg_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg_1 = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "tfidf_logReg_1.fit(tfidf_train_vecs, train_df['rating_1'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_tfidf_logReg_1 = tfidf_logReg_1.score(tfidf_test_vecs, test_df['rating_1'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy_tfidf_logReg_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg_7 = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "count_logReg_7.fit(count_train_vecs, train_df['rating_7'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_count_logReg_7 = count_logReg_7.score(count_test_vecs, test_df['rating_7'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy_count_logReg_7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg_7 = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "tfidf_logReg_7.fit(tfidf_train_vecs, train_df['rating_7'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_tfidf_logReg_7 = tfidf_logReg_7.score(tfidf_test_vecs, test_df['rating_7'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy_tfidf_logReg_7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg_28 = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "count_logReg_28.fit(count_train_vecs, train_df['rating_28'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_count_logReg_28 = count_logReg_28.score(count_test_vecs, test_df['rating_28'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy_count_logReg_28}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg_28 = LogisticRegression(multi_class=\"auto\", max_iter=100000)\n",
    "tfidf_logReg_28.fit(tfidf_train_vecs, train_df['rating_28'])\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy_tfidf_logReg_28 = tfidf_logReg_28.score(tfidf_test_vecs, test_df['rating_28'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy_tfidf_logReg_28}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = {\n",
    "    \"model\": [\"count accuracy:\", \"tfidf accuracy:\"],\n",
    "    \"t+1\": [accuracy_count_logReg_1, accuracy_tfidf_logReg_1],\n",
    "    \"t+7\": [accuracy_count_logReg_7, accuracy_tfidf_logReg_7],\n",
    "    \"t+28\": [accuracy_count_logReg_28, accuracy_tfidf_logReg_28]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame(accuracy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df_1 = accuracy_df\n",
    "accuracy_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tfidf_logReg_1.predict(tfidf_test_vecs)\n",
    "\n",
    "print(f\"30 Predictions: {predictions[:30]}\")\n",
    "print(f\"30 Actual Labels: {test_df['rating_1'][:30].to_list()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = tfidf_logReg_1.predict_proba(tfidf_test_vecs)\n",
    "pred_df = pd.DataFrame({\n",
    "    \"Prediction\": predictions,\n",
    "    \"Actual\": test_df['rating_1'],\n",
    "    \"P(Buy)\": [p[0] for p in probs],\n",
    "    \"P(Hold)\": [p[1] for p in probs],\n",
    "    \"P(Sell)\": [p[2] for p in probs]\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[(pred_df['Prediction'] == 'buy') & (pred_df['Actual'] == 'buy')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[(pred_df['Prediction'] == 'sell') & (pred_df['Actual'] == 'sell')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[pred_df['Prediction'] != pred_df['Actual']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - (183 / 791)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_df['rating_1'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(tfidf_logReg_1, tfidf_test_vecs, test_df['rating_1'], cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "precision_score(test_df['rating_1'], predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "X_train = tfidf_train_vecs\n",
    "y_train = train_df['rating_1']\n",
    "X_test = tfidf_test_vecs\n",
    "y_test = test_df['rating_1']\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(rf, X_test, y_test, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "df = pd.DataFrame({\"Feature\": feature_names,\n",
    "                   \"Importance\": importances\n",
    "                  })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"Importance\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.05, 0.5],\n",
    "             }\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Create first pipeline for base without reducing features.\n",
    "\n",
    "pipe = Pipeline([('classifier' , RandomForestClassifier())])\n",
    "# pipe = Pipeline([('classifier', RandomForestClassifier())])\n",
    "\n",
    "# Create param grid.\n",
    "\n",
    "param_grid = [\n",
    "    {'classifier' : [LogisticRegression()],\n",
    "     'classifier__penalty' : ['l1', 'l2'],\n",
    "    'classifier__C' : np.logspace(-4, 4, 20),\n",
    "    'classifier__solver' : ['liblinear']},\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__n_estimators' : list(range(10,101,10)),\n",
    "    'classifier__max_features' : list(range(6,32,5))}\n",
    "]\n",
    "\n",
    "# Create grid search object\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "\n",
    "# Fit on data\n",
    "\n",
    "best_clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = best_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions_test,\n",
    "                            target_names=[\"sell\", \"hold\", \"buy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['predictions'] = pd.Series(predictions_train)\n",
    "train_df[rejoin_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['predictions'] = pd.Series(predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('key').join(test_df.set_index('key'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "rejoin_df = pd.concat([test_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejoin_df = rejoin_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejoin_df[rejoin_df['return_1'] == 'hold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejoin_df[rejoin_df['predictions'] == rejoin_df['return_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(range(10,101,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(range(100,800,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "440d451a8cb861fd892fa5cffb1e989522135964a45ddfc7003ce2d688a295eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
